{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTGAN as a sampling technique for LIME and SHAP\n",
    "\n",
    "* Fooling LIME and SHAP: https://github.com/dylan-slack/Fooling-LIME-SHAP/blob/master/COMPAS_Example.ipynb\n",
    "* CTGAN: https://github.com/sdv-dev/CTGAN\n",
    "\n",
    "### Progress\n",
    "\n",
    "* If CTGAN is trained properly, we can identify about 43% of biased predictions (out of 1500 test samples from COMPAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "sys.path.append('/experiments/Fooling-LIME-SHAP/')\n",
    "\n",
    "from adversarial_models import Adversarial_Lime_Model\n",
    "from utils import one_hot_encode\n",
    "import pandas as pd\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "sys.path.append('/experiments/CTGAN')\n",
    "\n",
    "from ctgan import load_demo\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = load_demo()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "    'income'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ctgan import CTGANSynthesizer\n",
    "\n",
    "# ctgan = CTGANSynthesizer(batch_size=500, \n",
    "#                          gen_dim=[256,256],\n",
    "#                          dis_dim=[256,256],\n",
    "#                          l2scale=0, gen_lr=2e-8, dis_lr=2e-8)\n",
    "# ctgan.fit(data, discrete_columns, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctgan.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Always getting nans on adult dataset, try with the COMPAS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../experiments/')\n",
    "from dataset_utils import get_and_preprocess_compas_data\n",
    "\n",
    "data = get_and_preprocess_compas_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['age', 'two_year_recid', 'priors_count', 'length_of_stay', 'c_charge_degree_F', 'c_charge_degree_M', 'sex_Female', 'sex_Male', 'race']"
      ],
      "text/plain": [
       "['age',\n",
       " 'two_year_recid',\n",
       " 'priors_count',\n",
       " 'length_of_stay',\n",
       " 'c_charge_degree_F',\n",
       " 'c_charge_degree_M',\n",
       " 'sex_Female',\n",
       " 'sex_Male',\n",
       " 'race']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, cols = data['data'], data['target'], data['cols']\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6172, 9)\n",
      "(6172,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>c_charge_degree_F</th>\n",
       "      <th>c_charge_degree_M</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11001</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6172 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  two_year_recid  priors_count  length_of_stay  c_charge_degree_F  \\\n",
       "id                                                                            \n",
       "1       69               0             0               0                  1   \n",
       "3       34               1             0              10                  1   \n",
       "4       24               1             4               1                  1   \n",
       "7       44               0             0               1                  0   \n",
       "8       41               1            14               6                  1   \n",
       "...    ...             ...           ...             ...                ...   \n",
       "10996   23               0             0               1                  1   \n",
       "10997   23               0             0               1                  1   \n",
       "10999   57               0             0               1                  1   \n",
       "11000   33               0             3               1                  0   \n",
       "11001   23               1             2               1                  1   \n",
       "\n",
       "       c_charge_degree_M  sex_Female  sex_Male  race  \n",
       "id                                                    \n",
       "1                      0           0         1     0  \n",
       "3                      0           0         1     1  \n",
       "4                      0           0         1     1  \n",
       "7                      1           0         1     0  \n",
       "8                      0           0         1     0  \n",
       "...                  ...         ...       ...   ...  \n",
       "10996                  0           0         1     1  \n",
       "10997                  0           0         1     1  \n",
       "10999                  0           0         1     0  \n",
       "11000                  1           1         0     1  \n",
       "11001                  0           1         0     0  \n",
       "\n",
       "[6172 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an explainer around the ctgan sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../faster_lime/')\n",
    "\n",
    "def ridge_solve(tup):\n",
    "    data_synthetic_onehot, model_pred, weights = tup\n",
    "    solver = Ridge(alpha=1, fit_intercept=True)\n",
    "    solver.fit(data_synthetic_onehot,\n",
    "               model_pred,\n",
    "               sample_weight=weights.ravel())\n",
    "    \n",
    "    # Get explanations\n",
    "    importance = solver.coef_[\n",
    "        data_synthetic_onehot[0].toarray().ravel() == 1].ravel()\n",
    "    return importance\n",
    "\n",
    "class NumpyTabularExplainer:\n",
    "\n",
    "    def __init__(self, training_data, ctgan_sampler, feature_names=None,\n",
    "                 categorical_feature_idxes=None,\n",
    "                 qs=[25, 50, 75], **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            training_data:\n",
    "            feature_names:\n",
    "            categorical_feature_idxes:\n",
    "            qs:\n",
    "            **kwargs:\n",
    "\n",
    "        Assumptions:\n",
    "            * Data only contains categorical and/or numerical data\n",
    "            * Categorical data is already converted to ordinal labels (e.g. via scikit-learn's\n",
    "                OrdinalEncoder)\n",
    "\n",
    "        \"\"\"\n",
    "        self.training_data = training_data\n",
    "        self.num_features = self.training_data.shape[1]\n",
    "        self.ctgan_sampler = ctgan_sampler\n",
    "\n",
    "        # Parse columns\n",
    "        if feature_names is not None:\n",
    "            # TODO input validation\n",
    "            self.feature_names = list(feature_names)\n",
    "        else:\n",
    "            self.feature_names = list(range(self.num_features))\n",
    "        self.categorical_feature_idxes = categorical_feature_idxes\n",
    "        if self.categorical_feature_idxes:\n",
    "            self.categorical_features = [self.feature_names[i] for i in\n",
    "                                         self.categorical_feature_idxes]\n",
    "            self.numerical_features = list(set(self.feature_names) - set(self.categorical_features))\n",
    "            self.numerical_feature_idxes = [idx for idx in range(self.num_features) if\n",
    "                                            idx not in self.categorical_feature_idxes]\n",
    "        else:\n",
    "            self.categorical_features = []\n",
    "            self.numerical_features = self.feature_names\n",
    "            self.numerical_feature_idxes = list(range(self.num_features))\n",
    "\n",
    "        # Some book-keeping: keep track of the original indices of each feature\n",
    "        self.dict_feature_to_idx = {feature: idx for (idx, feature) in\n",
    "                                    enumerate(self.feature_names)}\n",
    "        self.list_reorder = [self.dict_feature_to_idx[feature] for feature in\n",
    "                             self.numerical_features + self.categorical_features]\n",
    "\n",
    "        # Get training data statistics\n",
    "        # Numerical feature statistics\n",
    "        if self.numerical_features:\n",
    "            training_data_num = self.training_data[:, self.numerical_feature_idxes]\n",
    "            self.sc = StandardScaler(with_mean=False)\n",
    "            self.sc.fit(training_data_num)\n",
    "            self.qs = qs\n",
    "            self.all_bins_num = np.percentile(training_data_num, self.qs, axis=0).T\n",
    "\n",
    "        # Categorical feature statistics\n",
    "        if self.categorical_features:\n",
    "            training_data_cat = self.training_data[:, self.categorical_feature_idxes]\n",
    "            self.dict_categorical_hist = {\n",
    "                feature: np.bincount(training_data_cat[:, idx]) / self.training_data.shape[0] for\n",
    "                (idx, feature) in enumerate(self.categorical_features)\n",
    "            }\n",
    "\n",
    "    def kernel_fn(self, distances, kernel_width):\n",
    "        return np.sqrt(np.exp(-(distances ** 2) / kernel_width ** 2))\n",
    "\n",
    "    def discretize(self, X, qs=[25, 50, 75], all_bins=None):\n",
    "        if all_bins is None:\n",
    "            all_bins = np.percentile(X, qs, axis=0).T\n",
    "        return (np.array([np.digitize(a, bins)\n",
    "                          for (a, bins) in zip(X.T, all_bins)]).T, all_bins)\n",
    "    \n",
    "    def explain_instance(self, data_row, predict_fn, num_estimators=10, label=0, num_samples=5000, num_features=10,\n",
    "                         kernel_width=None, **kwargs):\n",
    "        # Scale the data\n",
    "        data_row = data_row.reshape((1, -1))\n",
    "        \n",
    "        # Sample data using the CTGAN\n",
    "        data_samples = None\n",
    "        while data_samples is None:\n",
    "            try:\n",
    "                data_samples = self.ctgan_sampler.sample(int(num_estimators) * int(num_samples)).values\n",
    "            except:\n",
    "                data_samples = None\n",
    "                \n",
    "        for batch_idx in range(num_estimators):\n",
    "            data_samples[batch_idx * num_samples] = data_row.ravel()\n",
    "\n",
    "        # Split data into numerical and categorical data and process\n",
    "        list_orig = []\n",
    "        list_disc = []\n",
    "        if self.numerical_features:\n",
    "            data_num_synthetic = data_samples[:, self.numerical_feature_idxes]\n",
    "            # Discretize\n",
    "            data_synthetic_num_disc, _ = self.discretize(data_num_synthetic, self.qs,\n",
    "                                                         self.all_bins_num)\n",
    "            list_disc.append(data_synthetic_num_disc)\n",
    "            list_orig.append(data_num_synthetic)\n",
    "\n",
    "        if self.categorical_features:\n",
    "            # Sample from training distribution for each categorical feature\n",
    "            data_cat_synthetic = data_samples[:,self.categorical_feature_idxes]\n",
    "            list_disc.append(data_cat_synthetic)\n",
    "            list_orig.append(data_cat_synthetic)\n",
    "\n",
    "        # Concatenate the data and reorder the columns\n",
    "        data_synthetic_original = np.concatenate(list_orig, axis=1)\n",
    "        data_synthetic_disc = np.concatenate(list_disc, axis=1)\n",
    "        data_synthetic_original = data_synthetic_original[:, self.list_reorder]\n",
    "        data_synthetic_disc = data_synthetic_disc[:, self.list_reorder]\n",
    "\n",
    "        # Get model predictions (i.e. groundtruth)\n",
    "        model_pred = predict_fn(data_synthetic_original)\n",
    "\n",
    "        # Get distances between original sample and neighbors\n",
    "#         if self.numerical_features:\n",
    "#             distances = cdist(data_num_synthetic[:1], data_num_synthetic).reshape(-1, 1)\n",
    "#         else:\n",
    "        distances = cdist(data_synthetic_disc[:1], data_synthetic_disc).reshape(-1, 1)\n",
    "\n",
    "        # Weight distances according to some kernel (e.g. Gaussian)\n",
    "        if kernel_width is None:\n",
    "            kernel_width = np.sqrt(data_row.shape[1]) * 0.75\n",
    "        weights = self.kernel_fn(distances, kernel_width=kernel_width).ravel()\n",
    "\n",
    "        # Turn discretized data into onehot\n",
    "        data_synthetic_onehot = OneHotEncoder().fit_transform(data_synthetic_disc)\n",
    "\n",
    "        batch_size = num_samples\n",
    "        importances = []\n",
    "\n",
    "        iterator = ((data_synthetic_onehot[batch_idx * batch_size:(batch_idx + 1) * batch_size],\n",
    "                     model_pred[batch_idx * batch_size:(batch_idx + 1) * batch_size, label],\n",
    "                     weights[batch_idx * batch_size:(batch_idx + 1) * batch_size]) for batch_idx\n",
    "                    in range(num_estimators))\n",
    "\n",
    "        for tup in iterator:\n",
    "            # Solve\n",
    "            importance = ridge_solve(tup)\n",
    "            importances.append(importance)\n",
    "        \n",
    "        importances = np.mean(np.stack(importances), axis=0)\n",
    "#         # Solve\n",
    "#         solver = Ridge(alpha=1, fit_intercept=True)\n",
    "#         solver.fit(data_synthetic_onehot, model_pred[:, label], sample_weight=weights)\n",
    "\n",
    "#         # Get explanations\n",
    "#         importances = solver.coef_[data_synthetic_onehot[0].toarray().ravel() == 1]\n",
    "        explanations = sorted(list(zip(self.feature_names, importances)),\n",
    "                              key=lambda x: x[1], reverse=True)[:num_features]\n",
    "        return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>c_charge_degree_F</th>\n",
       "      <th>c_charge_degree_M</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11001</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6172 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  two_year_recid  priors_count  length_of_stay  c_charge_degree_F  \\\n",
       "id                                                                            \n",
       "1       69               0             0               0                  1   \n",
       "3       34               1             0              10                  1   \n",
       "4       24               1             4               1                  1   \n",
       "7       44               0             0               1                  0   \n",
       "8       41               1            14               6                  1   \n",
       "...    ...             ...           ...             ...                ...   \n",
       "10996   23               0             0               1                  1   \n",
       "10997   23               0             0               1                  1   \n",
       "10999   57               0             0               1                  1   \n",
       "11000   33               0             3               1                  0   \n",
       "11001   23               1             2               1                  1   \n",
       "\n",
       "       c_charge_degree_M  sex_Female  sex_Male  race  \n",
       "id                                                    \n",
       "1                      0           0         1     0  \n",
       "3                      0           0         1     1  \n",
       "4                      0           0         1     1  \n",
       "7                      1           0         1     0  \n",
       "8                      0           0         1     0  \n",
       "...                  ...         ...       ...   ...  \n",
       "10996                  0           0         1     1  \n",
       "10997                  0           0         1     1  \n",
       "10999                  0           0         1     0  \n",
       "11000                  1           1         0     1  \n",
       "11001                  0           1         0     0  \n",
       "\n",
       "[6172 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow along with what the attack did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a random column -- this is what we'll have LIME/SHAP explain.\n",
    "X['unrelated_column'] = np.random.choice([0,1],size=X.shape[0])\n",
    "features = [c for c in X]\n",
    "\n",
    "categorical_feature_name = ['two_year_recid', 'c_charge_degree_F', 'c_charge_degree_M',\\\n",
    "                            'sex_Female', 'sex_Male', 'race', 'unrelated_column']\n",
    "\n",
    "categorical_feature_indcs = [features.index(c) for c in categorical_feature_name]\n",
    "\n",
    "race_indc = features.index('race')\n",
    "unrelated_indcs = features.index('unrelated_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6620, Loss D: -0.0594\n",
      "Epoch 2, Loss G: 0.5143, Loss D: -0.1774\n",
      "Epoch 3, Loss G: 0.4983, Loss D: -0.4373\n",
      "Epoch 4, Loss G: 0.5133, Loss D: -0.4857\n",
      "Epoch 5, Loss G: 0.7596, Loss D: -0.8454\n",
      "Epoch 6, Loss G: 0.6868, Loss D: -0.5359\n",
      "Epoch 7, Loss G: 0.5844, Loss D: -0.1019\n",
      "Epoch 8, Loss G: 0.7323, Loss D: 0.0850\n",
      "Epoch 9, Loss G: 1.1881, Loss D: 0.1828\n",
      "Epoch 10, Loss G: 1.9654, Loss D: -0.6315\n",
      "Epoch 11, Loss G: 2.3582, Loss D: -1.7862\n",
      "Epoch 12, Loss G: 1.8220, Loss D: -2.3012\n",
      "Epoch 13, Loss G: 1.5083, Loss D: -1.7117\n",
      "Epoch 14, Loss G: 1.0188, Loss D: -1.0087\n",
      "Epoch 15, Loss G: 0.9358, Loss D: -0.6952\n",
      "Epoch 16, Loss G: 1.2328, Loss D: -0.9130\n",
      "Epoch 17, Loss G: 1.3974, Loss D: -0.6183\n",
      "Epoch 18, Loss G: 1.4387, Loss D: -0.6377\n",
      "Epoch 19, Loss G: 1.6189, Loss D: -0.4488\n",
      "Epoch 20, Loss G: 1.6137, Loss D: -0.8429\n",
      "Epoch 21, Loss G: 1.6490, Loss D: -1.1369\n",
      "Epoch 22, Loss G: 1.3284, Loss D: -1.1116\n",
      "Epoch 23, Loss G: 0.8969, Loss D: -0.8481\n",
      "Epoch 24, Loss G: 0.3866, Loss D: -0.8487\n",
      "Epoch 25, Loss G: -0.1017, Loss D: -0.3483\n",
      "Epoch 26, Loss G: -0.0946, Loss D: -0.1750\n",
      "Epoch 27, Loss G: 0.2719, Loss D: -0.2264\n",
      "Epoch 28, Loss G: 0.9997, Loss D: -0.5551\n",
      "Epoch 29, Loss G: 1.8164, Loss D: -0.7343\n",
      "Epoch 30, Loss G: 2.3619, Loss D: -0.9534\n",
      "Epoch 31, Loss G: 2.4555, Loss D: -0.9983\n",
      "Epoch 32, Loss G: 2.1160, Loss D: -1.1082\n",
      "Epoch 33, Loss G: 1.6882, Loss D: -0.8899\n",
      "Epoch 34, Loss G: 1.0743, Loss D: -0.4325\n",
      "Epoch 35, Loss G: 0.6040, Loss D: -0.3652\n",
      "Epoch 36, Loss G: 0.4694, Loss D: -0.5960\n",
      "Epoch 37, Loss G: 0.6343, Loss D: -0.9033\n",
      "Epoch 38, Loss G: 0.9960, Loss D: -1.0160\n",
      "Epoch 39, Loss G: 1.1962, Loss D: -0.9464\n",
      "Epoch 40, Loss G: 1.3514, Loss D: -0.9188\n",
      "Epoch 41, Loss G: 1.3343, Loss D: -0.4915\n",
      "Epoch 42, Loss G: 0.9665, Loss D: 0.0162\n",
      "Epoch 43, Loss G: 0.9972, Loss D: 0.3231\n",
      "Epoch 44, Loss G: 0.6723, Loss D: 0.2905\n",
      "Epoch 45, Loss G: 0.5580, Loss D: -0.1504\n",
      "Epoch 46, Loss G: 0.7031, Loss D: -0.9303\n",
      "Epoch 47, Loss G: 0.7854, Loss D: -1.5089\n",
      "Epoch 48, Loss G: 0.8615, Loss D: -1.5823\n",
      "Epoch 49, Loss G: 0.7155, Loss D: -1.7023\n",
      "Epoch 50, Loss G: 0.6135, Loss D: -1.3974\n",
      "Epoch 51, Loss G: 0.3581, Loss D: -0.7078\n",
      "Epoch 52, Loss G: 0.1617, Loss D: -0.4143\n",
      "Epoch 53, Loss G: 0.2358, Loss D: -0.0480\n",
      "Epoch 54, Loss G: 0.6715, Loss D: -0.0047\n",
      "Epoch 55, Loss G: 1.1907, Loss D: -0.1528\n",
      "Epoch 56, Loss G: 1.7631, Loss D: -0.1358\n",
      "Epoch 57, Loss G: 1.8031, Loss D: -0.2271\n",
      "Epoch 58, Loss G: 1.6144, Loss D: -0.2677\n",
      "Epoch 59, Loss G: 1.7350, Loss D: -0.6134\n",
      "Epoch 60, Loss G: 1.5153, Loss D: -0.9909\n",
      "Epoch 61, Loss G: 1.4947, Loss D: -1.1425\n",
      "Epoch 62, Loss G: 1.2118, Loss D: -1.3041\n",
      "Epoch 63, Loss G: 0.7472, Loss D: -1.4592\n",
      "Epoch 64, Loss G: 0.5740, Loss D: -1.2671\n",
      "Epoch 65, Loss G: 0.4113, Loss D: -0.9956\n",
      "Epoch 66, Loss G: 0.0166, Loss D: -0.6876\n",
      "Epoch 67, Loss G: -0.1503, Loss D: -0.3937\n",
      "Epoch 68, Loss G: 0.0655, Loss D: -0.3461\n",
      "Epoch 69, Loss G: 0.4831, Loss D: -0.3968\n",
      "Epoch 70, Loss G: 0.9274, Loss D: -0.3694\n",
      "Epoch 71, Loss G: 1.1136, Loss D: -0.4371\n",
      "Epoch 72, Loss G: 0.9268, Loss D: -0.3166\n",
      "Epoch 73, Loss G: 1.2029, Loss D: -0.2861\n",
      "Epoch 74, Loss G: 1.1433, Loss D: 0.0843\n",
      "Epoch 75, Loss G: 1.0580, Loss D: -0.6104\n",
      "Epoch 76, Loss G: 1.3357, Loss D: -0.9760\n",
      "Epoch 77, Loss G: 1.2343, Loss D: -1.2736\n",
      "Epoch 78, Loss G: 1.0869, Loss D: -1.2682\n",
      "Epoch 79, Loss G: 0.6328, Loss D: -1.3683\n",
      "Epoch 80, Loss G: 0.0035, Loss D: -0.7067\n",
      "Epoch 81, Loss G: -0.4825, Loss D: -0.3282\n",
      "Epoch 82, Loss G: -1.0177, Loss D: -0.1077\n",
      "Epoch 83, Loss G: -1.3687, Loss D: 0.0540\n",
      "Epoch 84, Loss G: -1.7435, Loss D: -0.3794\n",
      "Epoch 85, Loss G: -1.1034, Loss D: -0.1827\n",
      "Epoch 86, Loss G: -0.0352, Loss D: -0.5203\n",
      "Epoch 87, Loss G: 0.9497, Loss D: -0.8548\n",
      "Epoch 88, Loss G: 1.6702, Loss D: -0.7769\n",
      "Epoch 89, Loss G: 2.1854, Loss D: -0.4076\n",
      "Epoch 90, Loss G: 2.5356, Loss D: -0.2151\n",
      "Epoch 91, Loss G: 2.6828, Loss D: -0.4321\n",
      "Epoch 92, Loss G: 2.6419, Loss D: -0.4707\n",
      "Epoch 93, Loss G: 2.5313, Loss D: -0.6782\n",
      "Epoch 94, Loss G: 2.0439, Loss D: -0.9380\n",
      "Epoch 95, Loss G: 1.2795, Loss D: -0.8753\n",
      "Epoch 96, Loss G: 0.8431, Loss D: -0.9921\n",
      "Epoch 97, Loss G: 0.6867, Loss D: -0.9481\n",
      "Epoch 98, Loss G: 0.6866, Loss D: -0.8201\n",
      "Epoch 99, Loss G: 0.6355, Loss D: -0.3945\n",
      "Epoch 100, Loss G: 0.8280, Loss D: -0.1002\n"
     ]
    }
   ],
   "source": [
    "### Train the ctgan model\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "\n",
    "ctgan = CTGANSynthesizer()\n",
    "ctgan.fit(X, categorical_feature_name, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>c_charge_degree_F</th>\n",
       "      <th>c_charge_degree_M</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>race</th>\n",
       "      <th>unrelated_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  two_year_recid  priors_count  length_of_stay  c_charge_degree_F  \\\n",
       "0     19               1             1             -11                  0   \n",
       "1     40               1             0               0                  1   \n",
       "2     18               1             2               2                  1   \n",
       "3     19               0             2               3                  1   \n",
       "4     49               0             0               0                  1   \n",
       "..   ...             ...           ...             ...                ...   \n",
       "995   40               1             8               5                  1   \n",
       "996   60               0            15               0                  1   \n",
       "997   39               1            10              -3                  1   \n",
       "998   25               1             0               4                  1   \n",
       "999   35               1             3               3                  1   \n",
       "\n",
       "     c_charge_degree_M  sex_Female  sex_Male  race  unrelated_column  \n",
       "0                    1           0         1     0                 1  \n",
       "1                    1           0         0     1                 1  \n",
       "2                    0           1         1     0                 0  \n",
       "3                    1           0         1     1                 0  \n",
       "4                    1           1         1     1                 1  \n",
       "..                 ...         ...       ...   ...               ...  \n",
       "995                  0           0         1     0                 1  \n",
       "996                  1           0         0     0                 1  \n",
       "997                  0           0         1     0                 1  \n",
       "998                  1           0         1     0                 1  \n",
       "999                  1           0         0     0                 0  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctgan.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class racist_model_f:\n",
    "    # Decision rule: classify negatively if race is black\n",
    "    def predict(self,X):\n",
    "        return np.array([0 if x[race_indc] > 0 else 1 for x in X])\n",
    "\n",
    "    def predict_proba(self, X): \n",
    "        return one_hot_encode(self.predict(X))\n",
    "\n",
    "    def score(self, X,y):\n",
    "        return np.sum(self.predict(X)==y) / len(X)\n",
    "    \n",
    "class innocuous_model_psi:\n",
    "    # Decision rule: classify according to randomly drawn column 'unrelated column'\n",
    "    def predict(self,X):\n",
    "        return np.array([0 if x[unrelated_indcs] > 0 else 1 for x in X])\n",
    "\n",
    "    def predict_proba(self, X): \n",
    "        return one_hot_encode(self.predict(X))\n",
    "\n",
    "    def score(self, X,y):\n",
    "        return np.sum(self.predict(X)==y) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(X) is pd.DataFrame:\n",
    "    X = X.values\n",
    "\n",
    "# Split the data and normalize\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,y)\n",
    "xtest_not_normalized = deepcopy(xtest)\n",
    "# ss = StandardScaler().fit(xtrain)\n",
    "# xtrain = ss.transform(xtrain)\n",
    "# xtest = ss.transform(xtest)\n",
    "\n",
    "# Train the adversarial model for LIME with f and psi \n",
    "adv_lime = Adversarial_Lime_Model(racist_model_f(), innocuous_model_psi()).\\\n",
    "            train(xtrain, ytrain, feature_names=features, categorical_features=categorical_feature_indcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation on adversarial model:\n",
      " [('unrelated_column=0', 0.9982571500602809), ('sex_Male=1', 0.0007581075797357132), ('length_of_stay', -0.0003172374916087674)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's just look at a the first example in the test set\n",
    "ex_indc = np.random.choice(xtest.shape[0])\n",
    "\n",
    "\n",
    "# Now, lets look at the explanations on the adversarial model \n",
    "adv_explainer = lime.lime_tabular.LimeTabularExplainer(xtrain,feature_names=adv_lime.get_column_names(), \n",
    "                                                       discretize_continuous=False,\n",
    "                                                       categorical_features=categorical_feature_indcs)\n",
    "\n",
    "adv_exp = adv_explainer.explain_instance(xtest[ex_indc], adv_lime.predict_proba, labels=(0,1)).as_list(1)\n",
    "\n",
    "print (\"Explanation on adversarial model:\\n\",adv_exp[:3],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_explainer = NumpyTabularExplainer(\n",
    "    training_data=xtrain,\n",
    "    ctgan_sampler=ctgan,\n",
    "    feature_names=features,\n",
    "    categorical_feature_idxes=categorical_feature_indcs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit numpy_explainer.explain_instance(xtest[ex_indc], adv_lime.predict_proba, label=1, num_samples=1000, num_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[('race', 0.5016209270590931), ('length_of_stay', 0.01609617952506217), ('unrelated_column', 0.012876938185426817)]"
      ],
      "text/plain": [
       "[('race', 0.5016209270590931),\n",
       " ('length_of_stay', 0.01609617952506217),\n",
       " ('unrelated_column', 0.012876938185426817)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_explainer.explain_instance(xtest[ex_indc], adv_lime.predict_proba, label=1, num_samples=5000, num_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1543/1543 [36:36<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "list_exp = []\n",
    "for idx in tqdm(range(xtest.shape[0]), total=xtest.shape[0]):\n",
    "    exp = numpy_explainer.explain_instance(xtest[idx], adv_lime.predict_proba, label=1, num_samples=5000, num_features=3)\n",
    "    top = exp[0][0]\n",
    "    list_exp.append(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4387556707712249\n"
     ]
    }
   ],
   "source": [
    "print(len([a for a in list_exp if a == 'race']) / len(list_exp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
