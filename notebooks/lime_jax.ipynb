{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing LIME using JAX\n",
    "\n",
    "Notebook for experimenting with implementing LIME using JAX. To keep things simple, we will try to implement `LimeTabularExplainer` for the Wisconsin breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "from jax.ops import index, index_add, index_update\n",
    "\n",
    "import scipy\n",
    "import numpy as onp\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "X, y = data['data'], data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to obtain an explanation for a given data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30)\n",
      "[[0.01 0.99]]\n"
     ]
    }
   ],
   "source": [
    "data_row = X_test[0].reshape((1, -1))\n",
    "print(data_row.shape)\n",
    "print(clf.predict_proba(data_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the breast cancer dataset, all features are numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 2 2 2 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(0, 11).astype(onp.float32)\n",
    "bins = np.percentile(a, [25, 50, 75])\n",
    "bins\n",
    "print(onp.digitize(a, bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(arr, qs):\n",
    "    bins = np.percentile(a, qs)\n",
    "    return onp.digitize(a, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretize(a, [25, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([2.5, 5. , 7.5], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.04 ms ± 187 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit all_bins = np.percentile(X_test, [25, 50, 75], axis=0).T\n",
    "all_bins = np.percentile(X_test, [25, 50, 75], axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3)\n",
      "(114, 30)\n"
     ]
    }
   ],
   "source": [
    "print(all_bins.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 µs ± 52.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit discretized = [onp.digitize(a, bins) for (a, bins) in zip(X_test.T, all_bins)]\n",
    "discretized = [onp.digitize(a, bins) for (a, bins) in zip(X_test.T, all_bins)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(discretized).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[1, 3, 1, ..., 2, 1, 2],\n",
       "             [2, 0, 1, ..., 0, 0, 0],\n",
       "             [0, 0, 0, ..., 1, 2, 3],\n",
       "             ...,\n",
       "             [0, 0, 1, ..., 2, 1, 3],\n",
       "             [2, 0, 2, ..., 1, 1, 0],\n",
       "             [3, 1, 3, ..., 3, 2, 3]], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discretize(X, qs=[25, 50, 75], all_bins=None):\n",
    "    if all_bins is None:\n",
    "        all_bins = onp.percentile(X, qs, axis=0).T\n",
    "    return (np.array([onp.digitize(a, bins) for (a, bins) in zip(X.T, all_bins)]).T, all_bins)\n",
    "\n",
    "def discretize_jax(X, qs=[25, 50, 75], all_bins=None):\n",
    "    if all_bins is None:\n",
    "        all_bins = np.percentile(X, qs, axis=0).T\n",
    "    return (np.array([onp.digitize(a, bins) for (a, bins) in zip(X.T, all_bins)]).T, all_bins)\n",
    "\n",
    "X_test_disc, all_bins = discretize(X_test)\n",
    "X_test_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OneHotEncoder()\n",
    "X_test_onehot = oe.fit_transform(X_test_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 120)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_onehot[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.9 ms ± 8.23 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit X_synthetic = np.tile(X_test_onehot[0].toarray().reshape((1, -1)), (1000, 1))\n",
    "X_synthetic = np.tile(X_test_onehot[0].toarray().reshape((1, -1)), (1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 120)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synthetic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create synthetic dataset\n",
    "\n",
    "* Based on the implementation of LIME, it looks like we first standardscale the data, add noise from N(0, 1), then rescale back to the original domain\n",
    "* `with_mean=False` means that we are sampling around the given data instance\n",
    "* This requires getting the mean and std. dev. of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=False, with_std=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.41373011e+01, 1.92501319e+01, 9.20553407e+01, 6.55707033e+02,\n",
       "       9.66194286e-02, 1.05317868e-01, 8.86511730e-02, 4.88025670e-02,\n",
       "       1.81858681e-01, 6.29431429e-02, 4.08352527e-01, 1.22789495e+00,\n",
       "       2.87935604e+00, 4.03608396e+01, 7.07142857e-03, 2.55471033e-02,\n",
       "       3.15398914e-02, 1.16425363e-02, 2.07472923e-02, 3.83184901e-03,\n",
       "       1.63006923e+01, 2.57372527e+01, 1.07502308e+02, 8.83013407e+02,\n",
       "       1.33236022e-01, 2.58458879e-01, 2.73775407e-01, 1.14872464e-01,\n",
       "       2.92811209e-01, 8.44838462e-02])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sc.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.58120907e+00, 4.43143076e+00, 2.47414754e+01, 3.57395126e+02,\n",
       "       1.37498557e-02, 5.37530404e-02, 8.10522800e-02, 3.95191708e-02,\n",
       "       2.78833034e-02, 6.96823466e-03, 2.64846748e-01, 5.60209985e-01,\n",
       "       1.91800694e+00, 4.32565169e+01, 3.04915865e-03, 1.87691670e-02,\n",
       "       3.19594908e-02, 6.38187670e-03, 8.21410123e-03, 2.77416134e-03,\n",
       "       4.98288759e+00, 6.25536294e+00, 3.46495143e+01, 5.92290265e+02,\n",
       "       2.24146556e-02, 1.63066710e-01, 2.15216203e-01, 6.74248592e-02,\n",
       "       6.16088078e-02, 1.83893991e-02])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.550e+01, 2.108e+01, 1.029e+02, 8.031e+02, 1.120e-01, 1.571e-01,\n",
       "        1.522e-01, 8.481e-02, 2.085e-01, 6.864e-02, 1.370e+00, 1.213e+00,\n",
       "        9.424e+00, 1.765e+02, 8.198e-03, 3.889e-02, 4.493e-02, 2.139e-02,\n",
       "        2.018e-02, 5.815e-03, 2.317e+01, 2.765e+01, 1.571e+02, 1.748e+03,\n",
       "        1.517e-01, 4.002e-01, 4.211e-01, 2.134e-01, 3.003e-01, 1.048e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.3281472 , 4.75692866, 4.15900824, 2.24709276, 8.14554004,\n",
       "        2.92262538, 1.87780035, 2.14604705, 7.4775932 , 9.85041454,\n",
       "        5.1728028 , 2.16525951, 4.91343374, 4.08031004, 2.68861052,\n",
       "        2.07201524, 1.40584217, 3.35167867, 2.45675083, 2.09612899,\n",
       "        4.64991425, 4.42020715, 4.53397409, 2.95125567, 6.76789341,\n",
       "        2.4542103 , 1.95663706, 3.16500475, 4.87430305, 5.69893554]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_row = X_test[:1]\n",
    "data_row = sc.transform(data_row)\n",
    "data_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synthetic = np.tile(data_row, (1000, 1))\n",
    "X_synthetic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 3.03124   ,  4.307985  ,  4.8191566 , ...,  1.8983663 ,\n",
       "               5.2370872 ,  7.0021133 ],\n",
       "             [ 4.3552337 ,  4.9940343 ,  3.9476604 , ..., -0.27066302,\n",
       "               4.676184  ,  6.327023  ],\n",
       "             [ 4.5586944 ,  4.7614737 ,  4.5926437 , ...,  2.5451753 ,\n",
       "               2.3752594 ,  5.524213  ],\n",
       "             ...,\n",
       "             [ 3.5816717 ,  5.6939244 ,  3.6891572 , ...,  3.3720498 ,\n",
       "               3.9762788 ,  6.462904  ],\n",
       "             [ 3.3687832 ,  5.215034  ,  6.302809  , ...,  4.5297    ,\n",
       "               5.701255  ,  4.1892476 ],\n",
       "             [ 3.977677  ,  5.385982  ,  5.650092  , ...,  3.5632966 ,\n",
       "               5.409166  ,  5.876232  ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synthetic = X_synthetic + random.normal(key, (1000, 30))\n",
    "X_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.55000010e+01,  2.10799999e+01,  1.02899994e+02, ...,\n",
       "         2.13399991e-01,  3.00300002e-01,  1.04800001e-01],\n",
       "       [ 1.55970020e+01,  2.21307163e+01,  9.76709442e+01, ...,\n",
       "        -1.82494167e-02,  2.88094133e-01,  1.16350152e-01],\n",
       "       [ 1.63256378e+01,  2.11001415e+01,  1.13628784e+02, ...,\n",
       "         1.71608090e-01,  1.46336898e-01,  1.01586953e-01],\n",
       "       ...,\n",
       "       [ 1.28267155e+01,  2.52322311e+01,  9.12751923e+01, ...,\n",
       "         2.27359980e-01,  2.44973794e-01,  1.18848920e-01],\n",
       "       [ 1.20643167e+01,  2.31100616e+01,  1.55940781e+02, ...,\n",
       "         3.05414379e-01,  3.51247519e-01,  7.70377442e-02],\n",
       "       [ 1.42448931e+01,  2.38676071e+01,  1.39791611e+02, ...,\n",
       "         2.40254775e-01,  3.33252251e-01,  1.08060375e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Back to original domain\n",
    "X_synthetic = index_update(X_synthetic, index[0, :], data_row.ravel())\n",
    "X_synthetic_orig = sc.inverse_transform(X_synthetic)\n",
    "X_synthetic_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  ],\n",
       "       [0.88, 0.12],\n",
       "       [0.93, 0.07],\n",
       "       ...,\n",
       "       [0.94, 0.06],\n",
       "       [0.88, 0.12],\n",
       "       [0.89, 0.11]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred = clf.predict_proba(X_synthetic_orig)\n",
    "model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47 0.52 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68\n",
      " 0.69 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82\n",
      " 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96\n",
      " 0.97 0.98 0.99 1.  ]\n",
      "[0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
      " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
      " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
      " 0.42 0.43 0.48 0.53]\n"
     ]
    }
   ],
   "source": [
    "print(onp.unique(model_pred[:,0]))\n",
    "print(onp.unique(model_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[3, 3, 3, ..., 3, 2, 3],\n",
       "             [3, 3, 3, ..., 0, 2, 3],\n",
       "             [3, 3, 3, ..., 3, 0, 3],\n",
       "             ...,\n",
       "             [1, 3, 2, ..., 3, 0, 3],\n",
       "             [1, 3, 3, ..., 3, 3, 1],\n",
       "             [2, 3, 3, ..., 3, 3, 3]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synthetic_disc, all_bins = discretize(X_synthetic_orig, [25, 50, 75], all_bins)\n",
    "print(X_synthetic_disc.shape)\n",
    "X_synthetic_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 120)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synthetic_onehot = oe.transform(X_synthetic_disc)\n",
    "X_synthetic_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve\n",
    "\n",
    "* Get pairwise distances between original data and synthetic neighborhood\n",
    "* Weight using kernel function\n",
    "* Solve with ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = scipy.spatial.distance.cdist(X_synthetic[:1], X_synthetic)\n",
    "distances = distances.reshape(-1, 1)\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kernel_fn(distances, kernel_width=onp.sqrt(X_test.shape[1])):\n",
    "    return onp.sqrt(onp.exp(-(distances ** 2) / kernel_width ** 2))\n",
    "\n",
    "def kernel_fn_jax(distances, kernel_width=np.sqrt(X_test.shape[1])):\n",
    "    return np.sqrt(np.exp(-(distances ** 2) / kernel_width ** 2))\n",
    "\n",
    "weights = kernel_fn(distances).ravel()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "      random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = Ridge(alpha=1, fit_intercept=True)\n",
    "solver.fit(X_synthetic_onehot, model_pred[:,0], sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8382104246909032"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.score(X_synthetic_onehot, model_pred[:, 0], sample_weight=distances.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00518069])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.predict(X_synthetic_onehot[0].reshape((1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01465833, -0.01010554, -0.01213016, -0.00432731, -0.03096207,\n",
       "       -0.01130233, -0.00082199,  0.00186505, -0.03257237, -0.01411133,\n",
       "       -0.01285664,  0.01831899, -0.03420101, -0.01399956, -0.01165435,\n",
       "        0.01863359, -0.00679038, -0.01228653, -0.01411142, -0.008033  ,\n",
       "       -0.02562364, -0.0100659 , -0.00448154, -0.00105026, -0.02745177,\n",
       "       -0.03919753, -0.0011945 ,  0.02662247, -0.03499116, -0.02521414,\n",
       "       -0.00792308,  0.02690705, -0.00532627, -0.01080183, -0.01521744,\n",
       "       -0.00987581, -0.00251683, -0.00862203, -0.01535109, -0.01473138,\n",
       "        0.        ,  0.        , -0.01083942, -0.03038192, -0.02430588,\n",
       "       -0.00676988, -0.00536736, -0.00477822,  0.        ,  0.        ,\n",
       "        0.        , -0.04122134, -0.01178978,  0.        , -0.0009223 ,\n",
       "       -0.02850926, -0.01297373, -0.01119055, -0.0072997 , -0.00975736,\n",
       "       -0.01234457, -0.01268606, -0.00752261, -0.0086681 , -0.03239014,\n",
       "       -0.00663131,  0.0008185 , -0.00301839, -0.01079389, -0.00235066,\n",
       "       -0.01374421, -0.01433257, -0.01073425, -0.00630749, -0.00933138,\n",
       "       -0.01484822, -0.02245119, -0.01168523, -0.00059441, -0.00649052,\n",
       "       -0.04088116, -0.0430028 , -0.00027503,  0.04293765, -0.03130311,\n",
       "       -0.01096701,  0.00023033,  0.00081845, -0.07291057, -0.06738394,\n",
       "        0.02547783,  0.07359534, -0.05830185, -0.04269037,  0.00946557,\n",
       "        0.05030532, -0.02323844, -0.0100702 , -0.00334264, -0.00457005,\n",
       "       -0.04379145, -0.00391948,  0.00279705,  0.00369254, -0.05082128,\n",
       "       -0.04586416,  0.0228673 ,  0.03259681, -0.05431246, -0.0463561 ,\n",
       "       -0.00665383,  0.06610105, -0.020064  , -0.01135173, -0.00522634,\n",
       "       -0.00457926, -0.01779858, -0.01100411, -0.0043387 , -0.00807995])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_synthetic_onehot[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00432731,  0.00186505,  0.01831899,  0.01863359, -0.008033  ,\n",
       "       -0.00105026,  0.02662247,  0.02690705, -0.00987581, -0.01473138,\n",
       "       -0.03038192, -0.00536736, -0.04122134, -0.02850926, -0.00975736,\n",
       "       -0.0086681 , -0.00301839, -0.01433257, -0.00933138, -0.00649052,\n",
       "        0.04293765,  0.00023033,  0.07359534,  0.05030532, -0.00457005,\n",
       "        0.00369254,  0.03259681,  0.06610105, -0.00522634, -0.00807995])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = solver.coef_[X_synthetic_onehot[0].toarray().ravel() == 1]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst perimeter', 0.07359534433430019),\n",
       " ('worst concave points', 0.06610105228917687),\n",
       " ('worst area', 0.05030532099251261),\n",
       " ('worst radius', 0.042937650980115746),\n",
       " ('worst concavity', 0.032596814586122694),\n",
       " ('mean concave points', 0.026907048416998355),\n",
       " ('mean concavity', 0.02662246559710487),\n",
       " ('mean area', 0.018633585063711496),\n",
       " ('mean perimeter', 0.018318989973178268),\n",
       " ('worst compactness', 0.0036925373993616337)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(data['feature_names'], importances)), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lime.lime_tabular.LimeTabularExplainer at 0x7f1c221dddd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = LimeTabularExplainer(training_data=X_train, feature_names=data['feature_names'])\n",
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49 s ± 126 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit explainer.explain_instance(data_row=X_test[0], predict_fn=clf.predict_proba, labels=(0,))\n",
    "\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test[0],\n",
    "    predict_fn=clf.predict_proba,\n",
    "    labels=(0,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst concave points > 0.17', 0.13279641497505934),\n",
       " ('worst area > 1160.50', 0.1301029295944422),\n",
       " ('worst perimeter > 127.90', 0.11233780684855998),\n",
       " ('worst radius > 19.42', 0.0913769426073239),\n",
       " ('mean concavity > 0.14', 0.05182585077119412),\n",
       " ('mean concave points > 0.08', 0.04837277736026629),\n",
       " ('area error > 48.70', 0.04710720057726893),\n",
       " ('worst concavity > 0.40', 0.04301079412609855),\n",
       " ('perimeter error > 3.46', 0.026907726421716367),\n",
       " ('radius error > 0.50', 0.020634025278632246)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.as_list(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now make it end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_instance(training_data, data_instance, clf, qs=[25, 50, 75], num_samples=5000, num_features=10):\n",
    "    # Get training data statistics\n",
    "    all_bins = onp.percentile(training_data, qs, axis=0).T\n",
    "    \n",
    "    # Scale the data\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    sc.fit(training_data)\n",
    "    data_scaled = sc.transform(data_instance.reshape((1, -1)))\n",
    "    \n",
    "    # Create synthetic neighborhood\n",
    "    X_synthetic = onp.tile(data_scaled, (num_samples, 1))\n",
    "    X_synthetic = X_synthetic + onp.random.normal(size=(num_samples, training_data.shape[1]))\n",
    "    X_synthetic[0] = data_scaled.ravel()\n",
    "    X_synthetic_orig = sc.inverse_transform(X_synthetic)\n",
    "    X_synthetic_disc, all_bins = discretize(X_synthetic_orig, qs, all_bins)\n",
    "\n",
    "    # Get model predictions (i.e. groundtruth)\n",
    "    model_pred = clf.predict_proba(X_synthetic_orig)\n",
    "\n",
    "    # Solve\n",
    "    distances = scipy.spatial.distance.cdist(X_synthetic[:1], X_synthetic)\n",
    "    distances = distances.reshape(-1, 1)\n",
    "    weights = kernel_fn(distances, kernel_width=training_data.shape[1]).ravel()\n",
    "    solver = Ridge(alpha=1, fit_intercept=True)\n",
    "    oe = OneHotEncoder()\n",
    "    X_synthetic_onehot = oe.fit_transform(X_synthetic_disc)    \n",
    "    solver.fit(X_synthetic_onehot, model_pred[:,0], sample_weight=weights)\n",
    "    \n",
    "    # Explain\n",
    "    importances = solver.coef_[X_synthetic_onehot[0].toarray().ravel() == 1]\n",
    "    explanations = sorted(list(zip(data['feature_names'], importances)), \n",
    "                          key=lambda x: x[1], reverse=True)[:num_features]\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 ms ± 13.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit explain_instance(X_train, X_test[0], clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JAX version of the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_instance_jax(training_data, data_instance, clf, \n",
    "                         qs=[25, 50, 75], num_samples=5000, num_features=10):\n",
    "    # Get training data statistics\n",
    "    all_bins = np.percentile(training_data, qs, axis=0).T\n",
    "    \n",
    "    # Scale the data\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    sc.fit(training_data)\n",
    "    data_scaled = sc.transform(data_instance.reshape((1, -1)))\n",
    "    \n",
    "    # Create synthetic neighborhood\n",
    "    X_synthetic = np.tile(data_scaled, (num_samples, 1))\n",
    "    X_synthetic = X_synthetic + random.normal(key, (num_samples, training_data.shape[1]))\n",
    "    X_synthetic = index_update(X_synthetic, index[0, :], data_scaled.ravel())\n",
    "    X_synthetic_orig = sc.inverse_transform(X_synthetic)\n",
    "    X_synthetic_disc, all_bins = discretize_jax(X_synthetic_orig, qs, all_bins)\n",
    "    oe = OneHotEncoder()\n",
    "    X_synthetic_onehot = oe.fit_transform(X_synthetic_disc)\n",
    "    \n",
    "    # Get model predictions (i.e. groundtruth)\n",
    "    model_pred = clf.predict_proba(X_synthetic_orig)\n",
    "\n",
    "    # Solve\n",
    "    distances = scipy.spatial.distance.cdist(X_synthetic[:1], X_synthetic)\n",
    "    distances = distances.reshape(-1, 1)\n",
    "    weights = kernel_fn_jax(distances, kernel_width=training_data.shape[1]).ravel()\n",
    "    solver = Ridge(alpha=1, fit_intercept=True)\n",
    "    solver.fit(X_synthetic_onehot, model_pred[:,0], sample_weight=weights)\n",
    "    \n",
    "    # Explain\n",
    "    importances = solver.coef_[X_synthetic_onehot[0].toarray().ravel() == 1]\n",
    "    explanations = sorted(list(zip(data['feature_names'], importances)), \n",
    "                          key=lambda x: x[1], reverse=True)[:num_features]\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373 ms ± 52.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit explain_instance_jax(X_train, X_test[0], clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
